<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<link rel="alternate"
      type="application/rss+xml"
      href="https://dou-meishi.github.io/org-blog/rss.xml"
      title="RSS feed for https://dou-meishi.github.io/org-blog/">
<title>Convolution in CNN</title>
<meta name="author" content="Dou Meishi">
<meta name="referrer" content="no-referrer">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href= "https://gongzhitaao.org/orgcss/org.css" rel="stylesheet" type="text/css" />
<link href= "https://dou-meishi.github.io/org-blog/static/dou-org-blog.css" rel="stylesheet" type="text/css" />
<!-- Math Support by KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>
<body>
<div id="preamble" class="status"><div class="header">
  <div class="sitelinks">
    <a href="https://dou-meishi.github.io/org-blog/index.html">Home</a>
    |
    <a href="https://dou-meishi.github.io/org-blog/archive.html">All Posts</a>
  </div>
</div>
</div>
<div id="content">
<div class="post-date">04 Dec 2020</div><h1 class="post-title"><a href="https://dou-meishi.github.io/org-blog/2020-12-04-Conv2dNote/notes.html">Convolution in CNN</a></h1>
<nav id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org86ca42d">Input/Output</a></li>
<li><a href="#orgd8401fb">Parameters</a>
<ul>
<li><a href="#org18a189c">stride</a></li>
<li><a href="#orgcce0330">padding</a></li>
<li><a href="#org2f7da97">dilation</a></li>
</ul>
</li>
<li><a href="#org4b5b062">Correlation and Convolution</a></li>
<li><a href="#orgda9a597">References</a></li>
</ul>
</div>
</nav>
<p>
这篇笔记是对 <code>torch.nn.Conv2d</code> [ <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">官方文档</a> ] 的解释，
主要目标是弄清楚在这层 layer 中发生了什么：
输入输出是什么？是怎么从输入到输出的？
最后补充了一个困扰我很久的问题：
为什么要叫 convolution?
</p>
<div id="outline-container-org86ca42d" class="outline-2">
<h2 id="org86ca42d">Input/Output</h2>
<div class="outline-text-2" id="text-org86ca42d">
<p>
文档中明确给出了输入输出的类型：有四个维度 (N, C, H, W) 的 tensor,
用 NumPy 的术语来说就是 4d array.
其中
</p>

<ul class="org-ul">
<li>N: Batch size, 即样本的个数，或者说一次计算操作的图片张数。
注意，N 的大小完全不影响网络结构，
所以它也没有出现在构造网络所需的参数表里。
个人认为这个维度的存在完全是为了计算上的方便。
因为对数据库中不同的图片进行的操作是完全一样的，
所以在训练或者预测时不妨直接多张同时计算。
显然，这个维度的大小始终不变。
输入有多少张图片，
输出就是多少张图片对应的计算结果。
实际使用时让这个维度始终为 1 也可。
当然，如果要进行 BatchNorm 操作，
那输入样本数必须大于 1.</li>

<li>C: Channel size, 即图片的通道数。
若输入是 RGB 图像，C<sub>in</sub> 就是 3，若是灰度图像则为 1。
注意，输出的 Channel size 是不一样的，C<sub>out</sub> 应当理解为特征的通道。
后面会提到，在计算每一个输出通道的结果时，所有输入通道的图像数据都被用到了。
也就是说， <b>并不是</b> 对 R G B 三个通道的图像分别进行同样的处理。
这样即使输出只有 1 个通道，计算结果也会考虑颜色带来的影响。
在构造 Conv2d layer 时的两个必要参数就是 C<sub>in</sub> 和 C<sub>out</sub>。
实际使用时一般也仅需指定这两个参数 (外加一个 kernel size).</li>

<li>H &amp; W: 图片高度和宽度。注意， height 代表的维度是在 width 之前的。
所以像素坐标 (h, w) 代表的是图像从左上角开始数，向右数第 w 格，
往下数 h 格的像素点。和数学中常见的第一个维度代表横轴，第二个维度代表纵轴
非常不同。这两个维度的大小在输入输出中不必相同。
H<sub>out</sub>, W<sub>out</sub> 是依据 H<sub>in</sub>, W<sub>in</sub> 和一些其它参数自动确定的。
这种依赖关系是 convolution 操作本身决定的，所以不能直接指定输出的大小，
需要通过调整其他参数来间接实现。</li>
</ul>

<p>
总的来说，除去第一个维度 N, 输入和输出的 shape 是非常不同的.
C<sub>in</sub>, C<sub>out</sub> 需要在设计网络时就确定好，
H<sub>out</sub>, W<sub>out</sub> 则依赖于 H<sub>in</sub> 和 W<sub>out</sub>.
</p>
</div>
</div>
<div id="outline-container-orgd8401fb" class="outline-2">
<h2 id="orgd8401fb">Parameters</h2>
<div class="outline-text-2" id="text-orgd8401fb">
<p>
在介绍 Conv2d 的各种参数之前，先简单地介绍输出是怎样从输入算得的。官方
文档中给出的公式是 \[ output(N_i, C_{outj}) = bias(C_{outj}) +
\sum_{k}^{C_{in}-1} weight(C_{outj},k) \star input(N_i, k) \] 其中
\(\star\) 是 <b>correlation</b> 算符。
</p>

<p>
因为 input, output 都是 4d array, 所以指定 N, C 两个维度后得到的其实是矩阵。
上式其实是矩阵等式。
然后我们观察到 weight 和 N 无关，
这在前面已经解释了，因为 N 这个维度相当于数据库中样本的编号，
当然不可能每个样本都对应一套网络参数。
但这不代表 weight 就少了一个维度，它仍然是 4d array,
只不过 shape 和输入输入稍有不同，是 C<sub>out</sub>, C<sub>in</sub>, K, K.
而 K 是 kernel size.
如果我们让 N 和 C<sub>out</sub> 均为 1,
那么 output.shape 就是 1, 1, H<sub>out</sub>, W<sub>out</sub>,
等价于二维矩阵。
此时的计算过程等价于用 C<sub>in</sub> 个 K x K 大小的 kernel 分别对
每个输入 channel 的图像矩阵作滤波然后 <b>加权求和</b> 。
</p>

<p>
在最简单的情形，
N, C<sub>out</sub>, C<sub>in</sub> 都是 1 时，
只有一个 kernel，并且输入输出都可视为 2d array,
用 k 代表 kernel size.
那么输出可以写成
</p>

<pre class="example" id="orgfde8628">
output[i,j] = dot(kernel, input[i:i+k, j:j+k])
</pre>

<p>
这里 dot 表示将两个矩阵展开为一维向量后作内积。
这个公式可以用下图形象地表述。
</p>


<figure id="org80d1527">
<img src="./convolve-demo.gif" alt="convolve-demo.gif">

</figure>

<p>
上图中绿色的 image 表示输入矩阵，黄色的 3 x 3 矩阵代表 kernel,右边的红
色矩阵是输出结果。用这个公式可以计算出输出矩阵的形状。为了保证下标不越
界，需要 i + k ≤ H<sub>in</sub>, 同时 j + k ≤ W<sub>out</sub>, 所以 \[ H_{out}
= 1 + \max i = H_{in} - k + 1,\qquad W_{out} = 1 + \max j = W_{in} -
k + 1. \]
</p>
</div>
<div id="outline-container-org18a189c" class="outline-3">
<h3 id="org18a189c">stride</h3>
<div class="outline-text-3" id="text-org18a189c">
<p>
参数 stride 控制每次 kernel 滑动的步长，用公式表述就是
</p>

<pre class="example" id="org0c647d8">
output[i,j] = dot(kernel, input[stride*i:stride*i + k,
                                stride*j:stride*j + k])
</pre>


<figure id="org5b5d99b">
<img src="./convolve-stride.png" alt="convolve-stride.png">

</figure>
</div>
</div>
<div id="outline-container-orgcce0330" class="outline-3">
<h3 id="orgcce0330">padding</h3>
<div class="outline-text-3" id="text-orgcce0330">
<p>
从之前的公式看出，一般输出矩阵的大小是小于输入矩阵的。
要扩展输出矩阵大小也很简单，只要处理 input array 下标越界的问题就好了。
之前的处理方式成为 valid padding, 即不允许下标越界。
另一种处理方式是 zero padding, 即越界元素均视为 0.
zero padding 也有好几种方式，根据对下标越界的容身程度而定。
在 Conv2d 中用 padding 来控制 padding 方式。
</p>

<ul class="org-ul">
<li>padding=0 表示使用 valid padding, 不允许下标越界。</li>
<li>padding=1 表示使用 zero padding, 允许第一个指标为 -1 或 H<sub>in</sub>，  同时允许第二个指标为 -1 和 W<sub>in</sub> 并令此类访问的结果为 0.    其他类型的越界不被允许。</li>
<li>padding=2 同理，允许在横向和纵向越界两个元素。</li>
</ul>

<p>
对于 3 x 3 大小的 kernel, 如果 stride=1,
那么只要设置 padding=1 就能让输出输出有相同的大小。
</p>


<figure id="org4b36932">
<img src="./convolve-padding.gif" alt="convolve-padding.gif">

</figure>
</div>
</div>
<div id="outline-container-org2f7da97" class="outline-3">
<h3 id="org2f7da97">dilation</h3>
<div class="outline-text-3" id="text-org2f7da97">
<p>
控制 kernel 如何覆盖在输入矩阵上，用公式表述就是
</p>

<pre class="example" id="orgebd6a85">
output[i,j] = dot(kernel, input[i:i+k*dilation:dilation,
                                j:j+k*dilation:dilation])
</pre>


<figure id="orge285662">
<img src="./convolve-dilation.gif" alt="convolve-dilation.gif">

</figure>
</div>
</div>
</div>
<div id="outline-container-org4b5b062" class="outline-2">
<h2 id="org4b5b062">Correlation and Convolution</h2>
<div class="outline-text-2" id="text-org4b5b062">
<p>
我最早接触的 correlation, convolution 是在光学课上，
那里是对两个连续信号 f, g 定义的
</p>

$$
\begin{aligned}
f \ast g (t) &:= \int_{-\infty}^{\infty} f(\tau) g(t-\tau) d\tau,
\qquad ({\rm convolution})\\
f \star g(t) &:= \int_{-\infty}^{\infty} f(\tau) g(t+\tau) d\tau,
\qquad ({\rm correlation}).
\end{aligned}
$$

<p>
所以数学上说，我们之前计算的并不是 convolution, 而是 correlation.
我个人认为 convolution 是沿用了之前 filter 的称呼，
在那里 kernel 一般是中心对称的，
correlation, convolution 计算结果相同。
但最早没有接触图像处理中 filter 概念前这个称呼让我迷惑了很久，
一直没想明白为啥明明做的是
correlation 却叫 convolution.
</p>
</div>
</div>
<div id="outline-container-orgda9a597" class="outline-2">
<h2 id="orgda9a597">References</h2>
<div class="outline-text-2" id="text-orgda9a597">
<ul class="org-ul">
<li><a href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">Understanding of Convolutional Neural Network (CNN) — Deep Learning</a></li>
<li><a href="https://cs231n.github.io/convolutional-networks/#norm">Convolutional Neural Networks (CNNs / ConvNets)</a></li>
</ul>
</div>
</div>
<div class="taglist"><a href="https://dou-meishi.github.io/org-blog/tags.html">Tags</a>: <a href="https://dou-meishi.github.io/org-blog/tag-ai.html">ai</a> </div>
<div id="comments"><script src="https://giscus.app/client.js"
        data-repo="Dou-Meishi/org-blog"
        data-repo-id="R_kgDOLJfSOw"
        data-category="Announcements"
        data-category-id="DIC_kwDOLJfSO84CkxDd"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</div></div>
<div id="postamble" class="status">Created by <a href="https://github.com/bastibe/org-static-blog/">Org Static Blog</a>
</div>
</body>
</html>
